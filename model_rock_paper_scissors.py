# -*- coding: utf-8 -*-
"""notebook_Rock-Paper-Scissors.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1G5Nts33gpvrEEPs6wDtqQ4MLw6K-LlOe

# Image Classification
Python code for classifying rock, paper, scissors images


---


Nadhilah Mustikarini

@20221129
"""

import tensorflow as tf
print(tf.__version__)

# download the dataset
!wget --no-check-certificate \
  https://github.com/dicodingacademy/assets/releases/download/release/rockpaperscissors.zip \
  -O /tmp/rockpaperscissors.zip

# extract the dataset
import zipfile, os
local_zip = '/tmp/rockpaperscissors.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/tmp')
zip_ref.close()

os.listdir('/tmp/rockpaperscissors/rps-cv-images')

# split the folder into train and validation sets

!pip install split-folders

import splitfolders
splitfolders.ratio('/tmp/rockpaperscissors/rps-cv-images', output="/tmp/rockpaperscissors/rps-split", seed=1337, ratio=(0.6, 0.4))

os.listdir('/tmp/rockpaperscissors/rps-split/')

# check the number of files in each directory

import fnmatch

print(len(fnmatch.filter(os.listdir('/tmp/rockpaperscissors/rps-split/train/rock'), '*.png')),
      len(fnmatch.filter(os.listdir('/tmp/rockpaperscissors/rps-split/train/paper'), '*.png')),
      len(fnmatch.filter(os.listdir('/tmp/rockpaperscissors/rps-split/train/scissors'), '*.png'))
)

print(len(fnmatch.filter(os.listdir('/tmp/rockpaperscissors/rps-split/val/rock'), '*.png')),
      len(fnmatch.filter(os.listdir('/tmp/rockpaperscissors/rps-split/val/paper'), '*.png')),
      len(fnmatch.filter(os.listdir('/tmp/rockpaperscissors/rps-split/val/scissors'), '*.png'))
)

# define directory names for train and validation sets
base_dir = '/tmp/rockpaperscissors/rps-split'
train_dir = os.path.join(base_dir, 'train')
validation_dir = os.path.join(base_dir, 'val')

os.listdir('/tmp/rockpaperscissors/rps-split/train')

os.listdir('/tmp/rockpaperscissors/rps-split/val')

# image augmentation process on each sample in the dataset

from tensorflow.keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(
                    rescale= 1./225,
                    rotation_range=20,
                    horizontal_flip=True,
                    shear_range=0.2,
                    fill_mode='nearest')

validation_datagen = ImageDataGenerator(
                    rescale=1./255)

# image generator

train_generator = train_datagen.flow_from_directory(
        train_dir,
        target_size=(150,150),
        batch_size=4,
        class_mode='categorical')

validation_generator = validation_datagen.flow_from_directory(
        validation_dir,
        target_size=(150,150),
        batch_size=4,
        class_mode='categorical')

# building a Convolutional Neural Network (CNN) model

model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150,150,3)),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(256, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(512, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Dense(3, activation='softmax')
])

model.summary()

# compile the model 
model.compile(optimizer=tf.optimizers.Adam(),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# train the model
history = model.fit(
      train_generator,
      steps_per_epoch=30,
      epochs=50,
      validation_data=validation_generator,
      validation_steps=10,
      verbose=2)

model.evaluate(train_generator)

model.evaluate(validation_generator)

print(train_generator.class_indices)

# Commented out IPython magic to ensure Python compatibility.
# upload and predict images

import numpy as np
from google.colab import files
from tensorflow.keras.preprocessing import image
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
# %matplotlib inline

uploaded = files.upload()

for fn in uploaded.keys():

  path = fn
  img = image.load_img(path, target_size=(150,150))

  imgplot = plt.imshow(img)
  x = image.img_to_array(img)
  x = np.expand_dims(x, axis=0)
  images = np.vstack([x])

  classes = model.predict(images, batch_size=10)
  output_class = np.argmax(classes)

  print('\n',fn)

  if output_class==2:
    print('scissors')
  elif output_class==1:
    print('rock')
  else:
    print('paper')

classes